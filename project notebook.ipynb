{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 207 -Applied Machine Learning Project: Predicting Attrition of an Online Store Site\n",
    "\n",
    "#### Authors:\n",
    "\n",
    "Diego Moss\n",
    "Sammy Cayo\n",
    "Conor Huh\n",
    "Roz Huang\n",
    "Jasmine Lau\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data from BigQuery and Binding Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## code block for initial data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Data Pre-Processing and Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## code block for preprocessing\n",
    "\n",
    "## after binding rows we will need to extract the data from the columns with multiple data and put into their own columns\n",
    "\n",
    "## finally we need to manipulate and aggregate each user's data for each month for all the manipulated features in our list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## splitting data code block\n",
    "\n",
    "## need to see distribution of target variable and distribution of months in the data. If unequal need to sample so that the training set has roughly equal targets and months\n",
    "\n",
    "## may need to manually split the data, make sure we are splitting by user and not by rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Data Processing and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EDA\n",
    "\n",
    "## standardizing features based on the training distributions\n",
    "\n",
    "## look at how often we have missing values, decide whether we want to impute or drop them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fitting and Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## placeholder\n",
    "\n",
    "## we need to see how long it takes to fit one epoch, then do some math to see how many sets of hyperparameters we can test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## placeholder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
